import json
import torch
import torch.nn as nn
import numpy as np

from tqdm import tqdm

from sklearn.metrics.pairwise import cosine_similarity

from sentence_transformers import SentenceTransformer, models

from model_utils import generate
from common_utils import get_config

config = get_config()

ASPECTS = config["aspects"]

device = "cuda" if torch.cuda.is_available() else "cpu"

## Load PatentBERT ##
bert_embedding_model = models.Transformer('anferico/bert-for-patents', max_seq_length=128)
pooling_model = models.Pooling(bert_embedding_model.get_word_embedding_dimension())
dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(),
                            out_features=256, activation_function=nn.Tanh())
model = SentenceTransformer(modules=[bert_embedding_model, pooling_model, dense_model])
model.to(device)
model.eval()

batch_size = 512

def get_patent_bert_embeddings(concepts):
    """Get PatentBERT embeddings for the list of concepts"""
    with torch.inference_mode():
        features = model.encode(concepts, batch_size=512, convert_to_numpy=True, normalize_embeddings=True,
                                show_progress_bar=False, device=device)
        return features

def load_concepts(aspect):
    """Read the concepts from a JSON file for the given aspect"""
    path = f"dataset/classification/{aspect}"
    
    with open(f"{path}/concepts.json", 'r') as rf:
        concepts = json.load(rf)["concepts"]
    
    return concepts

concepts_dict = {
    aspect: load_concepts(aspect) for aspect in ASPECTS
}

embeddings_dict = {
    aspect: {
        concept: embedding
        for concept, embedding in zip(
            concepts_dict[aspect], get_patent_bert_embeddings(concepts_dict[aspect]))
    } for aspect in ASPECTS
}

def create_open_ended_question(template):
    """Create open ended question from a template"""
    question = template["question"]
    return question

def find_closest_concept(answer, aspect):
    """
        Find the closest concept from the concepts dict to the answer
        
        Args:
            answer: answer text generated by an LVLM for an open-ended question
            aspect: aspect to classifiy to
        
        Returns:
            most similar concept to the answer
    """
    embeddings = embeddings_dict[aspect]
    query_vector = model.encode(answer, convert_to_tensor=True, device=device,
                                    normalize_embeddings=True, show_progress_bar=False).cpu().numpy()
    index = np.array([v for _, v in embeddings.items()])
    
    scores = cosine_similarity(query_vector.reshape(1, -1), index).flatten()
    return list(embeddings.keys())[np.argmax(scores)]

def classify(model, loader, template, aspect):
    """
        Classify the figures using open-ended classification approach

        Args:
            model: LVLM to use for classification
            loader: figures to classify
            template: open-ended classification template to use for classification
            aspect: aspect to classify for

        Returns:
            List of classification labels for the figures
    """
    answers = {}

    for batch in tqdm(loader):

        ids = batch[0]
        ids = [id.item() if not isinstance(id, str) else id for id in ids]
        figures = batch[1]
        reference_answers = batch[2]

        questions = [create_open_ended_question(template) for _ in ids]
        outputs, _ = generate(model, figures, questions)

        for id, answer, reference_answer in zip(ids, outputs, reference_answers):
            answers.setdefault(id, {
                "reference_answer": reference_answer,
                "generated_answer": answer,
                "selected_answer": find_closest_concept(answer, aspect)
            })

    return answers

def compute_accuracy(answers):
    """Compute accuracy by comparing reference answer to selected answer"""
    acc = 0.0

    for _, sample in answers.items():
        reference_answer = sample["reference_answer"]
        selected_answer = sample["selected_answer"]
        if selected_answer == reference_answer:
            acc += 1.0
    
    accuracy = (acc / len(answers)) * 100
    print(f"{accuracy:.2f}%")